{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(r'/kaggle/input/dataset/data.csv', encoding='gbk')\n",
    "\n",
    "# 使用中位数填充缺失值\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 计算相关性并筛选特征\n",
    "correlations = {}\n",
    "for feature in df_imputed.columns[:-1]:\n",
    "    # 跳过唯一值的特征\n",
    "    if len(df_imputed[feature].unique()) == 1:\n",
    "        print(f\"Skipping constant feature: {feature}\")\n",
    "        continue\n",
    "    \n",
    "    # 跳过方差为零的特征\n",
    "    if df_imputed[feature].var() == 0:\n",
    "        print(f\"Skipping feature with zero variance: {feature}\")\n",
    "        continue\n",
    "    \n",
    "    # 计算斯皮尔曼等级相关系数的绝对值\n",
    "    corr, _ = spearmanr(df_imputed[feature], df_imputed[df_imputed.columns[-1]], nan_policy='omit')\n",
    "    correlations[feature] = abs(corr)\n",
    "\n",
    "# 按相关性降序排序并选择前15个特征\n",
    "sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "top_15_features = sorted_correlations[:15]\n",
    "\n",
    "print(\"Top 15 features without significant collinearity:\")\n",
    "for feature, corr in top_15_features:\n",
    "    print(f\"{feature}: {corr}\")\n",
    "\n",
    "# 导入numpy（已提前导入，此行可忽略或删除）\n",
    "import numpy as np\n",
    "\n",
    "# 选取排名前15的相关性特征名称\n",
    "selected_features = [f[0] for f in top_15_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DataFrame  float32 \n",
    "X = df_imputed.loc[:, selected_features].values.astype(np.float32)\n",
    "#  float32 \n",
    "y = df.iloc[:, -1].values.reshape(-1, 1).astype(np.float32)\n",
    "#  ndarray \n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "min_vals = np.min(X, axis=0)\n",
    "max_vals = np.max(X, axis=0)\n",
    "denominator = max_vals - min_vals\n",
    "denominator[denominator == 0] = 1 # 010\n",
    "# Min-Max\n",
    "normalized_X = (X - min_vals) / denominator\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(normalized_X, y, test_size=0.\n",
    "↪3)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "smote = SMOTE(k_neighbors=5, random_state=42,sampling_strategy=0.3)\n",
    "trainX, trainY = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svmModel = SVC(kernel='rbf',gamma='auto',class_weight={0: 1, 1: 6})\n",
    "svmModel.fit(trainX, trainY )\n",
    "svmLabels = svmModel.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, svmLabels)\n",
    "print('SVM :', accuracy)\n",
    "recall = recall_score(y_val, svmLabels, pos_label=1)\n",
    "print(':', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# \n",
    "dump(svmModel, 'svmModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "# \n",
    "t = DecisionTreeClassifier(max_leaf_nodes=10, random_state=42)\n",
    "# AdaBoost\n",
    "boostedTreeModel = AdaBoostClassifier(\n",
    "estimator=t,\n",
    "n_estimators=100,\n",
    "algorithm='SAMME',\n",
    "random_state=42\n",
    ")\n",
    "sample_weight = [1 if y == 0 else 10 for y in trainY]\n",
    "boostedTreeModel.fit(trainX, trainY, sample_weight=sample_weight)\n",
    "boostedTreeLabels = boostedTreeModel.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, boostedTreeLabels)\n",
    "print('Boosted Tree Accuracy:', accuracy)\n",
    "recall = recall_score(y_val, boostedTreeLabels, pos_label=1)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# \n",
    "dump(boostedTreeModel, 'boostedTreeModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "class_weights = {0: 1, 1: 5}\n",
    "logistic_model = LogisticRegression(class_weight=class_weights,random_state=42)\n",
    "logistic_model.fit(trainX, trainY)\n",
    "logistic_labels = logistic_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, logistic_labels)\n",
    "print('Logistic Regression Accuracy:', accuracy)\n",
    "recall = recall_score(y_val, logistic_labels, pos_label=1)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# \n",
    "dump(logistic_model, 'logistic_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 101\n",
    "class_weights = {0: 1, 1: 5}\n",
    "# \n",
    "trainX_weighted = []\n",
    "trainY_weighted = []\n",
    "for i, x in enumerate(trainX):\n",
    "trainX_weighted.append(x)\n",
    "trainY_weighted.append(trainY[i])\n",
    "if trainY[i] == 1:\n",
    "# \n",
    "for _ in range(class_weights[1] - 1):\n",
    "trainX_weighted.append(x)\n",
    "trainY_weighted.append(trainY[i])\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(trainX_weighted, trainY_weighted)\n",
    "lda_labels = lda_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, lda_labels)\n",
    "print('Fisher Linear Discriminant Analysis Accuracy:', accuracy)\n",
    "recall = recall_score(y_val, lda_labels, pos_label=1)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# \n",
    "dump(lda_model, 'lda_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "class_weight = {0: 1, 1: 100}\n",
    "# \n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "sample_weight = [1 if y == 0 else 100 for y in trainY]\n",
    "# \n",
    "clf.fit(trainX, trainY,sample_weight=sample_weight)\n",
    "# \n",
    "predictions = clf.predict(X_val)\n",
    "# \n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# \n",
    "recall = recall_score(y_val, predictions, pos_label=1)\n",
    "print(':', recall)\n",
    "from joblib import dump\n",
    "# \n",
    "dump(clf, 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from joblib import dump\n",
    "class_weights = {0: 1., 1: 5.} # 110\n",
    "# AdaBoost\n",
    "boosted_model = AdaBoostClassifier(\n",
    "n_estimators=60,\n",
    "algorithm='SAMME',\n",
    "random_state=42\n",
    ")\n",
    "# \n",
    "boosted_model.fit(trainX, trainY, sample_weight=[class_weights[yi] for yi in␣\n",
    "↪trainY])\n",
    "# \n",
    "boosted_labels = boosted_model.predict(X_val)\n",
    "# \n",
    "accuracy = accuracy_score(y_val, boosted_labels)\n",
    "recall = recall_score(y_val, boosted_labels, pos_label=1)\n",
    "print('Boosted Tree Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "# \n",
    "dump(boosted_model, 'boosted_model.joblib')\n",
    "# # \n",
    "# loaded_model = load('boosted_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,Activation,Dropout\n",
    "model=Sequential()\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Dense(64))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "class_weights={0:1,1:5}\n",
    "history=model.fit(trainX,trainY,\n",
    "epochs=100,\n",
    "shuffle=True,\n",
    "class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "y_pred_classes = (predictions > 0.5).astype(int)\n",
    "from sklearn.metrics import accuracy_score ,recall_score\n",
    "accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# 1\n",
    "recall = recall_score(y_val, y_pred_classes)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from keras.models import load_model\n",
    "model1=load('boostedTreeModel.joblib')\n",
    "model2=load('lda_model.joblib')\n",
    "model3=load('boosted_model.joblib')\n",
    "model4=load('logistic_model.joblib')\n",
    "model5=load('svmModel.joblib')\n",
    "model6=load('random_forest_model.joblib')\n",
    "model7=load_model('model.keras')\n",
    "# \n",
    "predictions1 = np.where(model1.predict(X_val) > 0.5, 1, 0)\n",
    "predictions2 = np.where(model2.predict(X_val) > 0.5, 1, 0)\n",
    "predictions3 = np.where(model3.predict(X_val) > 0.5, 1, 0)\n",
    "predictions4 = np.where(model4.predict(X_val) > 0.5, 1, 0)\n",
    "predictions5 = np.where(model5.predict(X_val) > 0.5, 1, 0)\n",
    "predictions6 = np.where(model6.predict(X_val) > 0.5, 1, 0)\n",
    "predictions7 = np.where(model7.predict(X_val) > 0.5, 1, 0)\n",
    "# \n",
    "weights = [0.3, 0.1, 0.5, 0.1, 0.2, 0.1,1] # \n",
    "# \n",
    "ans0=weights[0] * predictions1\n",
    "ans1=weights[1] * predictions2\n",
    "ans2=weights[2] * predictions3\n",
    "ans3=weights[3] * predictions4\n",
    "ans4=weights[4] * predictions5\n",
    "ans5=weights[5] * predictions6\n",
    "ans6=(weights[6] * predictions7).reshape(-1,)\n",
    "print(ans0.shape)\n",
    "print(ans1.shape)\n",
    "print(ans2.shape)\n",
    "print(ans3.shape)\n",
    "print(ans4.shape)\n",
    "print(ans5.shape)\n",
    "print(ans6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=(ans0+ans1+ans2+ans3+ans4+ans5+ans6)/np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0.5 \n",
    "binary_predictions = (ans > 0.5).astype(int)\n",
    "# \n",
    "print(\"Binary Predictions:\", binary_predictions)\n",
    "# \n",
    "accuracy = accuracy_score(y_val, binary_predictions)\n",
    "print(\"Weighted Classification Accuracy:\", accuracy)\n",
    "recall=recall_score(y_val, binary_predictions)\n",
    "print(\"Weighted Classification Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
